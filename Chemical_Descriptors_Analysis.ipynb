{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad39d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "base_dir = Path().resolve()\n",
    "file_name = \"Descriptors.xlsx\"\n",
    "file_path = base_dir / file_name\n",
    "data = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e6fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.info())\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29334797",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ad8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = data.select_dtypes(include=['number'])\n",
    "std_deviation = numeric_data.std()\n",
    "columns_to_drop = std_deviation[std_deviation == 0].index\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc1fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of data before outlier removal:\", data.shape)\n",
    "numeric_data = data.select_dtypes(include=['number'])\n",
    "mask = pd.Series([True] * len(data), index=data.index)\n",
    "for col in numeric_data.columns:\n",
    "    mean = data[col].mean()\n",
    "    std = data[col].std()\n",
    "    lower_bound = mean - 3 * std\n",
    "    upper_bound = mean + 3 * std\n",
    "    mask &= data[col].between(lower_bound, upper_bound)\n",
    "data = data[mask]\n",
    "print(\"Shape of data after outlier removal:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c8c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = data.select_dtypes(include=['number'])\n",
    "scaler = StandardScaler()\n",
    "data_normalized = pd.DataFrame(scaler.fit_transform(numeric_data), columns=numeric_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(data_normalized)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1])\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title('Redukcja wymiarowości PCA (2 składniki główne)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Wyjaśniona wariancja:\", pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7133d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['MolWt', 'Chi0n', 'TPSA', 'NumHAcceptors', 'fr_benzene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d709af",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [var for var in variables if var in data.columns and var in data_normalized.columns]\n",
    "print(f\"Variables used: {variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(variables), figsize=(5 * len(variables), 5))\n",
    "for ax, col in zip(axes, variables):\n",
    "    sns.boxplot(x=data[col], ax=ax)\n",
    "    ax.set_title(f'Boxplot {col} (before normalization)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(variables), figsize=(5 * len(variables), 5))\n",
    "for ax, col in zip(axes, variables):\n",
    "    sns.boxplot(x=data_normalized[col], ax=ax)\n",
    "    ax.set_title(f'Boxplot {col} (after normalization)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ee705",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(variables), figsize=(5 * len(variables), 5))\n",
    "for ax, col in zip(axes, variables):\n",
    "    ax.hist(data[col], bins=30, edgecolor='black')\n",
    "    ax.set_title(f'Histogram {col} (before normalization)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d684eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(variables), figsize=(5 * len(variables), 5))\n",
    "for ax, col in zip(axes, variables):\n",
    "    ax.hist(data_normalized[col], bins=30, edgecolor='black')\n",
    "    ax.set_title(f'Histogram {col} (after normalization)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(combinations(variables, 2))\n",
    "for x, y in pairs:\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.scatterplot(x=data[x], y=data[y])\n",
    "    plt.title(f'Scatter plot: {x} vs {y} (before normalization)')\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd96c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=data_normalized[variables])\n",
    "plt.suptitle(\"Pairplot zmiennych po normalizacji\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in pairs:\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.scatterplot(x=data_normalized[x], y=data_normalized[y])\n",
    "    plt.title(f'Scatter plot: {x} vs {y} (after normalization)')\n",
    "    plt.xlabel(f'{x} (normalized)')\n",
    "    plt.ylabel(f'{y} (normalized)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in variables:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(data[var], kde=True, bins=30, color='skyblue')\n",
    "    plt.title(f'Histogram for {var} before normalization')\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(data_normalized[var], kde=True, bins=30, color='salmon')\n",
    "    plt.title(f'Histogram for {var} after normalization')\n",
    "    plt.xlabel(f'{var} (normalized)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "class RegressionModel:\n",
    "    def __init__(self, X, y, min_beta=None, max_beta=None, delta=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.min_beta = min_beta\n",
    "        self.max_beta = max_beta\n",
    "        self.delta = delta\n",
    "        self.model = LinearRegression()\n",
    "        self.y_pred = None\n",
    "        self.coef = None\n",
    "        self.intercept = None\n",
    "        self.r2 = None\n",
    "        self.mse = None\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Train the regression model and enforce coefficient constraints\"\"\"\n",
    "        self.model.fit(self.X, self.y)\n",
    "        self.y_pred = self.model.predict(self.X)\n",
    "        self.coef = self.model.coef_\n",
    "        self.intercept = self.model.intercept_\n",
    "        self.r2 = self.model.score(self.X, self.y)\n",
    "        self.mse = np.mean((self.y - self.y_pred) ** 2)\n",
    "\n",
    "        print(\"Regression coefficients:\", self.coef)\n",
    "        print(\"Intercept:\", self.intercept)\n",
    "        print(f'R²: {self.r2:.4f}, MSE: {self.mse:.4f}')\n",
    "        if self.min_beta is not None:\n",
    "            self.coef = np.maximum(self.coef, self.min_beta)\n",
    "        if self.max_beta is not None:\n",
    "            self.coef = np.minimum(self.coef, self.max_beta)\n",
    "\n",
    "    def plot_explanatory_vs_response(self):\n",
    "        \"\"\"Plot explanatory variable vs response variable (only for simple linear regression)\"\"\"\n",
    "        if self.X.shape[1] == 1:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(self.X, self.y, alpha=0.7, color='blue')\n",
    "            plt.xlabel(\"Explanatory Variable (X)\")\n",
    "            plt.ylabel(\"Response Variable (y)\")\n",
    "            plt.title(\"Scatter Plot: Explanatory vs Response Variable\")\n",
    "            plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"plot_explanatory_vs_response: Only available for simple linear regression (1 explanatory variable).\")\n",
    "\n",
    "    def plot_regression(self):\n",
    "        \"\"\"Plot regression if only one predictor variable exists\"\"\"\n",
    "        if self.X.shape[1] == 1:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(self.X, self.y, color='blue', alpha=0.5)\n",
    "            plt.plot(self.X, self.y_pred, color='red', linewidth=2)\n",
    "            plt.title('Linear Regression')\n",
    "            plt.xlabel('X')\n",
    "            plt.ylabel('y')\n",
    "            plt.text(0.05, 0.95,\n",
    "                     f'Slope: {self.coef[0]:.2f}\\nIntercept: {self.intercept:.2f}\\nR²: {self.r2:.2f}\\nMSE: {self.mse:.2f}',\n",
    "                     transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.5))\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"plot_regression: Only available for simple linear regression (1 explanatory variable).\")\n",
    "\n",
    "    def plot_residuals(self):\n",
    "        \"\"\"Plot residuals\"\"\"\n",
    "        residuals = self.y - self.y_pred\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(self.y_pred, residuals, alpha=0.7)\n",
    "        plt.axhline(y=0, color='red', linestyle='-')\n",
    "        plt.xlabel('Predicted values')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.title('Residual Plot')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.text(0.02, 0.95,\n",
    "                 f'Mean of Residuals: {np.mean(residuals):.4f}\\nStd Dev: {np.std(residuals):.4f}',\n",
    "                 transform=plt.gca().transAxes, bbox=dict(facecolor='white', alpha=0.7))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_qq(self):\n",
    "        \"\"\"Plot Q-Q plot for residuals\"\"\"\n",
    "        residuals = self.y - self.y_pred\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "        plt.title(\"Q-Q Plot for Residuals\")\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "        plt.show()\n",
    "print(\"=== Multiple Regression Example ===\")\n",
    "X_multi = np.random.rand(100, 2) * 100  \n",
    "y_multi = 3 * X_multi[:, 0] + 2 * X_multi[:, 1] + np.random.randn(100) * 10 \n",
    "\n",
    "min_beta_multi = np.array([0, 1])\n",
    "max_beta_multi = np.array([5, 5])\n",
    "delta_multi = np.array([0.1, 0.2])\n",
    "\n",
    "regression_multi = RegressionModel(X_multi, y_multi, min_beta_multi, max_beta_multi, delta_multi)\n",
    "regression_multi.fit()\n",
    "\n",
    "regression_multi.plot_explanatory_vs_response()\n",
    "regression_multi.plot_regression()\n",
    "regression_multi.plot_residuals()\n",
    "regression_multi.plot_qq()\n",
    "print(\"\\n=== Simple Linear Regression Example ===\")\n",
    "X_simple = np.random.rand(100, 1) * 100  \n",
    "y_simple = 4 * X_simple[:, 0] + np.random.randn(100) * 10\n",
    "\n",
    "min_beta_simple = np.array([0])\n",
    "max_beta_simple = np.array([5])\n",
    "delta_simple = np.array([0.1])\n",
    "\n",
    "regression_simple = RegressionModel(X_simple, y_simple, min_beta_simple, max_beta_simple, delta_simple)\n",
    "regression_simple.fit()\n",
    "\n",
    "regression_simple.plot_explanatory_vs_response()\n",
    "regression_simple.plot_regression()\n",
    "regression_simple.plot_residuals()\n",
    "regression_simple.plot_qq()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MyLinearRegression:\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "        XtX = np.dot(X.T, X)\n",
    "        Xty = np.dot(X.T, y)\n",
    "        beta = np.linalg.pinv(XtX).dot(Xty)\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            self.intercept_ = beta[0]\n",
    "            self.coef_ = beta[1:].flatten()\n",
    "        else:\n",
    "            self.intercept_ = 0.0\n",
    "            self.coef_ = beta.flatten()\n",
    "\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not self.is_fitted:\n",
    "            raise Exception(\"The model is not fitted yet. Please call fit() first.\")\n",
    "        \n",
    "        X = np.array(X)\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "            beta = np.hstack([self.intercept_, self.coef_])\n",
    "        else:\n",
    "            beta = self.coef_\n",
    "        \n",
    "        return np.dot(X, beta)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y = np.array(y)\n",
    "        residual_sum_of_squares = ((y - y_pred) ** 2).sum()\n",
    "        total_sum_of_squares = ((y - y.mean()) ** 2).sum()\n",
    "        return 1 - residual_sum_of_squares / total_sum_of_squares\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"fit_intercept\": self.fit_intercept}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "\n",
    "    def plot(self, X, y):\n",
    "        \"\"\"\n",
    "        Plots the data points and the regression line (for 1D X).\n",
    "        \"\"\"\n",
    "        if X.shape[1] != 1:\n",
    "            raise ValueError(\"Plotting is only supported for single feature (1D) data.\")\n",
    "\n",
    "        y_pred = self.predict(X)\n",
    "\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.scatter(X, y, color=\"blue\", label=\"Data points\")\n",
    "        plt.plot(X, y_pred, color=\"red\", label=\"Regression line\")\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"y\")\n",
    "        plt.title(\"Linear Regression\")\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68331d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([2, 4, 5, 4, 5])\n",
    "model = MyLinearRegression()\n",
    "model.fit(X, y)\n",
    "model.plot(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f256fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "normalized_data = pd.DataFrame(scaler.fit_transform(data.select_dtypes(include=['float64', 'int64'])), \n",
    "columns=data.select_dtypes(include=['float64', 'int64']).columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd06202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df):\n",
    "    return df[(np.abs(df - df.mean()) <= (3 * df.std())).all(axis=1)]\n",
    "\n",
    "clean_data = remove_outliers(data.select_dtypes(include=['float64', 'int64']))\n",
    "normalized_clean_data = remove_outliers(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b387a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(['MolWt', 'Chi0n', 'TPSA', 'NumHAcceptors', 'fr_benzene']), 2, figsize=(12, 20))\n",
    "for i, var in enumerate(['MolWt', 'Chi0n', 'TPSA', 'NumHAcceptors', 'fr_benzene']):\n",
    "    sns.boxplot(data=data, y=var, ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f\"Boxplot: {var} (oryginalne)\")\n",
    "\n",
    "    sns.boxplot(data=normalized_data, y=var, ax=axes[i, 1])\n",
    "    axes[i, 1].set_title(f\"Boxplot: {var} (znormalizowane)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig, axes = plt.subplots(len(['MolWt', 'Chi0n', 'TPSA', 'NumHAcceptors', 'fr_benzene']), 2, figsize=(12, 20))\n",
    "for i, var in enumerate(['MolWt', 'Chi0n', 'TPSA', 'NumHAcceptors', 'fr_benzene']):\n",
    "    sns.histplot(data=data, x=var, kde=True, ax=axes[i, 0])\n",
    "    axes[i, 0].set_title(f\"Histogram: {var} (oryginalne)\")\n",
    "\n",
    "    sns.histplot(data=normalized_data, x=var, kde=True, ax=axes[i, 1])\n",
    "    axes[i, 1].set_title(f\"Histogram: {var} (znormalizowane)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447eb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "fig, axes = plt.subplots(10, 1, figsize=(6, 40))\n",
    "combs = list(combinations([\"MolWt\", \"Chi0n\", \"TPSA\", \"NumHAcceptors\", \"fr_benzene\"], 2))\n",
    "for i, (x, y) in enumerate(combs[:10]):\n",
    "    sns.scatterplot(x=normalized_data[x], y=normalized_data[y], ax=axes[i])\n",
    "    axes[i].set_title(f\"{x} vs {y}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f1c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinearRegression:\n",
    "    def __init__(self, min_beta, max_beta, delta):\n",
    "        self.min_beta = np.array(min_beta)\n",
    "        self.max_beta = np.array(max_beta)\n",
    "        self.delta = np.array(delta)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = np.c_[np.ones(X.shape[0]), X]\n",
    "        self.y = y\n",
    "        self.beta = np.linalg.inv(self.X.T @ self.X) @ self.X.T @ self.y\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_b = np.c_[np.ones(X.shape[0]), X]\n",
    "        return X_b @ self.beta\n",
    "\n",
    "    def mse(self):\n",
    "        y_pred = self.predict(self.X[:, 1:])\n",
    "        return np.mean((self.y - y_pred) ** 2)\n",
    "\n",
    "    def r_squared(self):\n",
    "        y_pred = self.predict(self.X[:, 1:])\n",
    "        ss_res = np.sum((self.y - y_pred)**2)\n",
    "        ss_tot = np.sum((self.y - np.mean(self.y))**2)\n",
    "        return 1 - ss_res / ss_tot\n",
    "\n",
    "    def summary(self):\n",
    "        print(\"MSE:\", self.mse())\n",
    "        print(\"R²:\", self.r_squared())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40010eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalized_data[[\"MolWt\", \"Chi0n\", \"TPSA\", \"NumHAcceptors\"]]\n",
    "y = normalized_data[\"fr_benzene\"]\n",
    "\n",
    "model = CustomLinearRegression(min_beta=[-10]*5, max_beta=[10]*5, delta=[0.01]*5)\n",
    "model.fit(X.values, y.values)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be9fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_molwt = data_normalized[[\"MolWt\"]]\n",
    "y_target = data_normalized[\"fr_benzene\"]\n",
    "model_1d = CustomLinearRegression(min_beta=[-10, -10], max_beta=[10, 10], delta=[0.01, 0.01])\n",
    "model_1d.fit(X_molwt.values, y_target.values)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_molwt, y_target, label=\"Dane\")\n",
    "plt.plot(X_molwt, model_1d.predict(X_molwt.values), color=\"red\", label=\"Regresja\")\n",
    "plt.xlabel(\"MolWt (znormalizowane)\")\n",
    "plt.ylabel(\"fr_benzene (znormalizowane)\")\n",
    "plt.title(\"Regresja liniowa: MolWt -> fr_benzene\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed130657",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = model.y - model.predict(X.values)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(x=model.predict(X.values), y=residuals)\n",
    "plt.axhline(y=np.mean(residuals), color='r', linestyle='--')\n",
    "plt.title(\"Rezydua vs Predykcja\")\n",
    "plt.xlabel(\"y_hat\")\n",
    "plt.ylabel(\"Rezydua\")\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q plot dla rezyduów\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
